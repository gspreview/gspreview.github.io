<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description>graphscope blog</description>
    <link>https://graphscope.io/blog/</link>
    <atom:link href="https://graphscope.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 07 Mar 2022 02:02:26 +0000</pubDate>
    <lastBuildDate>Mon, 07 Mar 2022 02:02:26 +0000</lastBuildDate>
    <generator>Jekyll v4.2.2</generator>
    
      <item>
        <title>Release Notes: v0.11.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
We are glad to announce a number of new features and improvements to GraphScope, alongside the GraphScope v0.11.0 release. This major release introduces mutable graphs into GraphScope, and adds GPU supports for graph analytics engine (GAE). It also focuses on user-friendly improvements, code quality, and a series of bug fixes.&lt;/p&gt;

&lt;p&gt;We highlight the following improvements included in this release:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Supporting mutable graphs:
    &lt;ul&gt;
      &lt;li&gt;Providing a set of interfaces (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;add_vertex&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;add_edge&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;update_vertex&lt;/code&gt;) to modify the topology of an existing graph;&lt;/li&gt;
      &lt;li&gt;Adopting existing apps to mutable graphs.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Accelerating graph analytics apps with GPUs:
    &lt;ul&gt;
      &lt;li&gt;Adding new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fragment&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;worker&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;message_manager&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apps&lt;/code&gt; to utilize GPUs to process graph analytics tasks faster;&lt;/li&gt;
      &lt;li&gt;On top of these new infrastructures, 6 example algorithms (BFS, WCC, SSSP, PageRank, CDLP and LCC) are implemented;&lt;/li&gt;
      &lt;li&gt;Our GPU-based graph algorithms are about 2x faster compared with state-of-the-art  GPU-based graph processing systems. See detals in &lt;a href=&quot;https://github.com/alibaba/libgrape-lite/blob/master/Performance.md#performance-on-gpus&quot;&gt;performance report&lt;/a&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Optimizations and enhancements:
    &lt;ul&gt;
      &lt;li&gt;Stream grpc request (response) to support loading graph (fetching result) from (to) numpy/pandas more than 2GB;&lt;/li&gt;
      &lt;li&gt;Accelerating manipulation of graph topology by replacing folly::dynamicwith &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rapidjson::value&lt;/code&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.11.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Sun, 06 Mar 2022 03:33:20 +0000</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2022/03/06/release-notes.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2022/03/06/release-notes.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.10.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
We are glad to announce the availability of GraphScope v0.10. This release supports users to run GraphScope on MacOS powered by Apple’s new M1 chip. In addition, it allows to serialize/deserialize graph data to/from the disk under the standalone mode.&lt;/p&gt;

&lt;p&gt;We highlight the following improvements included in this release:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add Apple’s M1 chip support.&lt;/li&gt;
  &lt;li&gt;Improve the implementation and documentation of context selectors.&lt;/li&gt;
  &lt;li&gt;Support serialization/deserialization of graph data on the standalone mode.&lt;/li&gt;
  &lt;li&gt;Refactor &lt;a href=&quot;https://github.com/alibaba/GraphScope/tree/main/analytical_engine/java&quot;&gt;Java SDK&lt;/a&gt; in Graph Analytics Engine.&lt;/li&gt;
  &lt;li&gt;Fix a bug when loading graph data from HDFS.&lt;/li&gt;
  &lt;li&gt;Fix got empty result in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;all_simple_path&lt;/code&gt;algorithm with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_workers=1&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.10.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Wed, 05 Jan 2022 03:33:20 +0000</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2022/01/05/release-notes.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2022/01/05/release-notes.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.9.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
We are glad to announce the availability of GraphScope v0.9. In this release, we revisit the Dev-infra to improve productivity. Now, you can enjoy GraphScope with standalone mode in both our &lt;a href=&quot;https://try.graphscope.app/&quot;&gt;PlayGround&lt;/a&gt; and &lt;a href=&quot;https://colab.research.google.com/github/alibaba/GraphScope&quot;&gt;Google Colab&lt;/a&gt;. We also continuously make GraphScope more user-friendly and update the &lt;a href=&quot;https://graphscope.io/docs/installation.html&quot;&gt;documents&lt;/a&gt; and &lt;a href=&quot;https://github.com/alibaba/GraphScope/tree/main/tutorials&quot;&gt;tutorials&lt;/a&gt; based on the latest version. Further, we have preliminary supported Java in Graph Analytics Engine (GAE), and users can succinctly develop graph analytics applications with Java (see &lt;a href=&quot;https://graphscope.io/docs/analytics_engine.html#writing-your-own-algorithms-in-java.&quot;&gt;this document&lt;/a&gt; for more details).&lt;/p&gt;

&lt;p&gt;On the performance side, we have done a lot of work to improve the performance of the distributed GAIA engine, which is used to execute graph interactive queries in GraphScope. The improvements include but are not limited to 1) simplifying the communication protocol that reduces many useless tags in correlated subtask; 2) making early-stop mechanism more effective due to 1); 3) resolving a lot of bugs due to 1); 4) refining the engine apis. As a distributed cyclic data-parallel engine, GAIA engine is in de-facto generic to handle any data-intensive task. Now users can assess to more &lt;a href=&quot;https://github.com/alibaba/GraphScope/tree/main/research/engine/pegasus/pegasus/src/api&quot;&gt;GAIA APIs&lt;/a&gt; (will be well documented) to play with the engine.&lt;/p&gt;

&lt;p&gt;We highlight the following improvements included in this release:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;New features:
    &lt;ul&gt;
      &lt;li&gt;Support GLE (Graph Learning Engine) on MacOS;&lt;/li&gt;
      &lt;li&gt;GIE (Graph Interactive Engine) Runtime refactoring based on the new GAIA engine;&lt;/li&gt;
      &lt;li&gt;Reimplement persistent storage engine with zero-copy read;&lt;/li&gt;
      &lt;li&gt;Add several popular &lt;a href=&quot;https://github.com/alibaba/GraphScope/tree/main/python/graphscope/dataset&quot;&gt;datasets&lt;/a&gt; and ship datasets by adding an extra container in Kubernetes mode;&lt;/li&gt;
      &lt;li&gt;Support NetworkX generator, read, write, drawing, convert with more generators and test cases;&lt;/li&gt;
      &lt;li&gt;Add common labels following Kubernetes best practice to GraphScope cluster;&lt;/li&gt;
      &lt;li&gt;Add transformation ability for directed/undirected graphs;&lt;/li&gt;
      &lt;li&gt;Java SDK in GAE, and examples to write and run algorithms written in Java.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bug Fixes:
    &lt;ul&gt;
      &lt;li&gt;Fix a crash if duplicate property names were encountered when extracting subgraphs;&lt;/li&gt;
      &lt;li&gt;Fix the MPI library not found problem on macOS;&lt;/li&gt;
      &lt;li&gt;Fix context processing on graphs generated by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;add_column&lt;/code&gt;;&lt;/li&gt;
      &lt;li&gt;Fix many bugs related to subtasks while querying Gremlin;&lt;/li&gt;
      &lt;li&gt;Fix a failure when exposing Gremlin service deployed with Helm Charts.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.9.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Wed, 08 Dec 2021 03:33:20 +0000</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2021/12/08/release-notes-0.9.0.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/12/08/release-notes-0.9.0.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.8.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
We are glad to announce the availability of GraphScope v0.8. This release is a major update on many aspects of the project including deployment, system speed and APIs. For quickly getting started, this release supports to use GraphScope on standalone mode without Kubernetes. To improve the efficiency of operators and applications in NetworkX module, an immutable graph is applied by default, while it is converted to a dynamic graph only if modification operators for graphs are triggered. In addition, a notebook is integrated into the helm charts.&lt;/p&gt;

&lt;p&gt;We highlight the following improvements included in this release:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Standalone mode support for GraphScope:
    &lt;ul&gt;
      &lt;li&gt;Users now can do &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip install graphscope&lt;/code&gt; to deploy GraphScope together with runtime dependencies;&lt;/li&gt;
      &lt;li&gt;Users now switch to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip install graphscope_client&lt;/code&gt; to install python client of GraphScope;&lt;/li&gt;
      &lt;li&gt;MacOS support is added, and it is compatible with Apple clang 13.0.0.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Enhancement on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;graphscope.nx&lt;/code&gt; module:
    &lt;ul&gt;
      &lt;li&gt;Support NetworkX operators over immutable graphs;&lt;/li&gt;
      &lt;li&gt;Support holding an immutable graph in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nx.Graph&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;copy-on-write&lt;/code&gt; to a dynamic graph.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Enhancement of deployment, performance and APIs:
    &lt;ul&gt;
      &lt;li&gt;Integrate a jupyter-lab notebook container into the helm charts.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.8.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Sat, 06 Nov 2021 03:33:20 +0000</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2021/11/06/release-notes-0.8.0.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/11/06/release-notes-0.8.0.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.7.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
We are glad to announce the availability of GraphScope v0.7. This release includes major updates for the persistent graph store in GraphScope, providing APIs for real-time graph updates (inserts and deletes of individual vertices and edges). It also focuses on user-friendly improvements, security issues, code quality, and a series of bug fixes.&lt;/p&gt;

&lt;p&gt;We highlight the following improvements included in this release:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Apart from bulk loading, this release introduces a set of APIs for real-time graph updates. Currently, these APIs have supported the following functions:
    &lt;ul&gt;
      &lt;li&gt;Insert/delete one or multiple vertices/edges;&lt;/li&gt;
      &lt;li&gt;Update properties of a specific vertex/edge.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;More details can refer to &lt;a href=&quot;https://github.com/alibaba/GraphScope/blob/main/docs/persistent_graph_store.rst#realtime-write&quot;&gt;this&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;User-friendly improvement
    &lt;ul&gt;
      &lt;li&gt;Revise error handling in GraphScope and improve all error messages reported to users;&lt;/li&gt;
      &lt;li&gt;Add a &lt;a href=&quot;https://github.com/alibaba/GraphScope/blob/main/docs/persistent_graph_store.rst&quot;&gt;document&lt;/a&gt; to describe persistent graph store in GraphScope;&lt;/li&gt;
      &lt;li&gt;The logs in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;err&lt;/code&gt; channel are always fetched to the client for debugging;&lt;/li&gt;
      &lt;li&gt;The &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/download/v0.7.0/graphscope_store_data_load.tar.gz&quot;&gt;bulk-loading tool&lt;/a&gt; of the persistent graph store is released to help load graphs into the store;&lt;/li&gt;
      &lt;li&gt;Revise some descriptions for APIs in documents.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Optimizations and enhancements
    &lt;ul&gt;
      &lt;li&gt;Using &lt;a href=&quot;https://github.com/etcd-io/zetcd&quot;&gt;zetcd&lt;/a&gt; to replace zookeeper in the graph interactive engine;&lt;/li&gt;
      &lt;li&gt;Update third-party dependencies to address some security issues;&lt;/li&gt;
      &lt;li&gt;More test coverages for GAIA and client;&lt;/li&gt;
      &lt;li&gt;Integrate GIE GraphManager into Coordinator;&lt;/li&gt;
      &lt;li&gt;During &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sess.gremlin&lt;/code&gt;, the pod will not be created dynamically for reducing the response time.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Some Breaking API Changes:
    &lt;ul&gt;
      &lt;li&gt;Remove GIE GraphManager role;&lt;/li&gt;
      &lt;li&gt;Remove zookeeper and replace with zetcd;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k8s_gie_graph_manager_image&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k8s_gie_graph_manager_cpu&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k8s_gie_graph_manager_mem&lt;/code&gt; Deprecated;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k8s_zookeeper_image&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k8s_zookeeper_cpu&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k8s_zookeeper_mem&lt;/code&gt; Deprecated;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k8s_gie_gremlin_server_cpu&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k8s_gie_gremlin_server_mem&lt;/code&gt; Deprecated.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.7.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Wed, 08 Sep 2021 03:33:20 +0000</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2021/09/08/release-notes-0.7.0.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/09/08/release-notes-0.7.0.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.6.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
We are glad to announce the release of GraphScope 0.6. This major release integrates a new graph interactive engine GAIA, which supports efficient parallel execution and bounded-memory execution for Gremlin queries. More technical details of GAIA can refer to our published &lt;a href=&quot;https://graphscope.io/blog/tech/2021/08/05/GAIA-Deep-Dive-Bounded-Memory-Execution-and-Early-Stop-Optimization-for-Efficient-Graph-Traversal-at-Scale.html&quot;&gt;tech blog&lt;/a&gt;. Note that currently the integration of GAIA with GraphScope is experimental, and is not recommended for production use yet! In addition, this release improves the experience of local deployment on MacOS, Ubuntu and CentOS, and adds more graph analytics algorithms.&lt;/p&gt;

&lt;p&gt;We highlight the following improvements included in this release:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;[Experimental] Integrate GAIA, a graph interactive query engine, into GraphScope. Currently, it has supported the following features/functions:
    &lt;ul&gt;
      &lt;li&gt;Dynamic memory management for arbitrary graph traversal with ensuring bounded use of memory;&lt;/li&gt;
      &lt;li&gt;Automatic and adaptive strategy for optimizing Gremlin traversal, such as hybrid DFS/BFS traversal to balance parallelism and memory usage;&lt;/li&gt;
      &lt;li&gt;Early-stop optimization for Gremlin (limit, nested conditional, etc.) to minimize wasted computation;&lt;/li&gt;
      &lt;li&gt;Improvement of performance and scalability (a new LDBC Social Network Benchmark will be released around year end);&lt;/li&gt;
      &lt;li&gt;Support both Vineyard and the new persistent graph store.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lazy evaluation support for graph interactive engine and graph learning engine.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A &lt;a href=&quot;https://github.com/alibaba/GraphScope/blob/main/scripts/deploy_local.sh&quot;&gt;script&lt;/a&gt; supporting local deployment on MacOS, Ubuntu and CentOS.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Add more graph analytics algorithms as built-in applications.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.boundary.node_boundary.html#networkx.algorithms.boundary.node_boundary&quot;&gt;node_boundary&lt;/a&gt; and &lt;a href=&quot;https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.boundary.edge_boundary.html#networkx.algorithms.boundary.edge_boundary&quot;&gt;edge_boundary&lt;/a&gt; applications;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html#networkx.algorithms.link_analysis.pagerank_alg.pagerank&quot;&gt;pagerank&lt;/a&gt; in NetworkX version;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.simple_paths.is_simple_path.html#networkx.algorithms.simple_paths.is_simple_path&quot;&gt;is_simple_path&lt;/a&gt; application.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.6.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Sun, 08 Aug 2021 03:33:20 +0000</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2021/08/08/release-notes-0.6.0.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/08/08/release-notes-0.6.0.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>GAIA Deep Dive: Bounded-Memory Execution and Early-Stop Optimization for Efficient Graph Traversal at Scale</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/gaia.png&quot; alt=&quot;knife&quot; /&gt;
&lt;a href=&quot;https://graphscope.io/blog/tech/2021/04/29/Introducing-gaia-a-scalable-engine-for-gremlin-the-sql-for-graphs.html&quot;&gt;Last time&lt;/a&gt;, we presented an overview of the GAIA engine for scaling Gremlin for large distributed graphs. In contrast to other, existing batch-oriented big graph processing systems, such as &lt;a href=&quot;https://research.google/pubs/pub37252&quot;&gt;Google Pregel&lt;/a&gt;, &lt;a href=&quot;https://giraph.apache.org/&quot;&gt;Apache Giraph&lt;/a&gt;, &lt;a href=&quot;https://github.com/jegonzal/PowerGraph&quot;&gt;GraphLab PowerGraph&lt;/a&gt;, and &lt;a href=&quot;https://spark.apache.org/graphx/&quot;&gt;Apache Spark GraphX&lt;/a&gt;, GAIA focuses on low-latency graph traversal at scale. Achieving this goal requires a different distributed infrastructure. Today, we continue to explain why with highlighting two unique and key features of GAIA.&lt;/p&gt;

&lt;h3 id=&quot;bounded-memory-execution&quot;&gt;Bounded-Memory Execution&lt;/h3&gt;

&lt;p&gt;Graph traversal can produce paths of arbitrary length, leading to memory usage growing exponentially with the number of hops. Although it is very common for Gremlin queries to terminate with a top-k constraint and/or aggregate operation, such an explosion of &lt;em&gt;intermediate&lt;/em&gt; results can often lead to memory crisis, especially in an interactive environment with limited memory configuration.&lt;/p&gt;

&lt;p&gt;On the other hand, the traversal strategies can greatly impact the memory usage. There are two typical traversal strategies, namely (breadth-first-search) BFS-like traversal and (depth-like-search) DFS-like traversal. BFS-like traversal can better utilize parallelism, while it may produce data all at once that drives high the memory usage. On the contrary, DFS-like traversal tends to consume much less memory, while it may suffer from low parallelism.&lt;/p&gt;

&lt;p&gt;To ensure &lt;em&gt;bounded-memory execution&lt;/em&gt; without sacrificing performance (parallelism), GAIA employs &lt;em&gt;dynamic scheduling&lt;/em&gt; for executing each Gremlin operator.  GAIA packs a segment of consecutive data entries in an input stream into a single batch, and such a batch constitutes the finest data granularity for communication and computation. A &lt;em&gt;task&lt;/em&gt; can be logically viewed as the combination of an operator and a batch of data entries to be computed. GAIA dynamically creates such tasks corresponding to each operator when there is one or more batches available from all its inputs, and maintains all the tasks in a same scheduling queue to share resources.&lt;/p&gt;

&lt;p&gt;Furthermore, GAIA can schedule tasks with priorities according to the occurrence order of its corresponding operators in a Gremlin query. Specifically, it can schedule the operators that appear first with higher priority for a BFS-like traversal, and prioritize those that appear last to follow a DFS-like traversal. To balance the memory usage with the performance (parallelism), GAIA by default adopts a hybrid traversal strategy, that is, it uses BFS-prioritized scheduling as it has better opportunities for parallelization, and automatically switches to DFS-prioritized in case that the current operator arrives at the memory bound.&lt;/p&gt;

&lt;p&gt;To validate the hypothesis, we use the following cycle-detection query as an example to compare GAIA with the current &lt;a href=&quot;https://github.com/alibaba/GraphScope/tree/main/interactive_engine&quot;&gt;MaxGraph release&lt;/a&gt; in GraphScope without memory control.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;g.V([vertices]).as('a').repeat(out().simplePath())
	.times(k-1)
	.out().where(as('a'))
	.path().limit(n)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above cycle-detection query starts from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt; (default 10) vertices in V, it traverses from V via at most &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt; (default 3) hops, and returns at most &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; cycles found along the traversal.&lt;/p&gt;

&lt;p&gt;We generate large LDBC data sets with scale factor 30. The generated LDBC data sets which have 89 million vertices and 541 million edges would be used for the following experiments. In this experiment, we set memory upper bound of GAIA to 256MB, and compare with MaxGraph. For this query, We vary the number of start vertices, set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt; to 3 and set result limit to infinity. We report both the query latency and max memory consumption in the following.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/memory-bound.jpg&quot; alt=&quot;memory-bound.jpg&quot; height=&quot;50%&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As the figure shows, GAIA achieves much lower memory usage (up to 9× memory saving) comparing to MaxGraph as well as comparable performance. We can see the actual memory usage of all cases in GAIA is very close to the bounded value 256MB. This expriment shows that GAIA ensure &lt;em&gt;bounded-memory execution&lt;/em&gt; without sacrificing performance (parallelism) thanks to powerful dynamic scheduling.&lt;/p&gt;

&lt;h3 id=&quot;early-stop-optimization&quot;&gt;Early-Stop Optimization&lt;/h3&gt;

&lt;p&gt;Traversing all candidate paths fully is often unnecessary, especially for interactive queries with dynamic conditions running on diverse input graphs. For example, in the above query, only the first &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt; results are needed. This leads to an interesting tradeoff between parallel traversal and wasted computation, as further illustrated in the following figure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/early_stop_case.jpg&quot; alt=&quot;early_stop_case.png&quot; height=&quot;50%&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The figure shows an example run of the query with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k=1&lt;/code&gt;. The circle denotes the traversal specified by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;repeat&lt;/code&gt;-loop. Assume we have enough computation resource (CPU cores), the paths can be explored in a fully parallel fashion. However, once a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4&lt;/code&gt;-hop path is found, all the remaining parallel traversal will be no longer required.&lt;/p&gt;

&lt;p&gt;For real-world queries on large graph data, such wasted computation can be hidden deeply in nested traversals (e.g., a predicate that can be evaluated early from partial inputs) and significantly impact query performance. While avoiding such wastage is straightforward in a sequential implementation, it is challenging to do so for a fully-parallel execution.&lt;/p&gt;

&lt;p&gt;To minimize such wastage, GAIA tracks data dependencies dynamically at runtime. When enough results are collected, the system automatically creates a &lt;em&gt;cancellation token&lt;/em&gt; that is sent backward along input streams to its upstream operators within the same execution context. The token serves as a signal for receiving operators to clear any unsent output data and immediately cancel any on-going computation for the particular output stream. Such cancellation notification is implemented at a system level by GAIA. Below, we continue to use the cycle-detection query as a running example to demonstrate that such early-stop optimization can significantly improve query performance.&lt;/p&gt;

&lt;p&gt;In this experiment, we vary the number of result limit and report the latency of GAIA and MaxGraph.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/early-stop.jpg&quot; alt=&quot;early-stop.jpg&quot; height=&quot;50%&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The figure shows that GAIA outpeforms MaxGraph in all cases thanks to the ablility of cancelling wasted computation. GAIA achieves 4.5× better performance in average, up to 8.1×. Even the number of limit results is close to the complete query result, GAIA can also show better performance due to the fine-grained early-stop mechanism. Note that MaxGraph can also achieve low latency when the limit size is small (50), this is because a naive early-stop is implemented in MaxGraph to cancel the job from source operator to the end when already collected needed results. But the performance degrades rapidly when the limit size become larger due to coarse-grained job cancelling in MaxGraph.&lt;/p&gt;

&lt;h3 id=&quot;scalability&quot;&gt;Scalability&lt;/h3&gt;

&lt;p&gt;Finally, we study the scalability while running the same query as above. This is to prove that both features do not introduce additional overheads that impact performance/scalability of GAIA.&lt;/p&gt;

&lt;p&gt;In this experiment, we set the query result limit to infinity and vary the number of computing threads to show the scale-up performance of GAIA. We test the scalability using different size of queries by varying the number of start vertices.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/gaia-scalability.jpg&quot; alt=&quot;gaia-scalability.jpg&quot; height=&quot;50%&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As we can see from the above figure, GAIA has linear scalability in all type (both large and small) of queries. It shows that new features such as dynamic scheduling do not hurt the scalability of GAIA.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Diverse and irregular graph data and algorithms impose significant challenges in efficient distributed and parallel execution. Implementation choices can have a huge impact on system performance and memory requirements. GAIA is the first engine to support efficient graph traversal at scale that enables bounded-memory execution with minimum wastage. It will be included as an experimental feature in the coming release of GraphScope v0.6.0. We welcome community feedback!&lt;/p&gt;
</description>
        <pubDate>Thu, 05 Aug 2021 03:10:42 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2021/08/05/GAIA-Deep-Dive-Bounded-Memory-Execution-and-Early-Stop-Optimization-for-Efficient-Graph-Traversal-at-Scale.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2021/08/05/GAIA-Deep-Dive-Bounded-Memory-Execution-and-Early-Stop-Optimization-for-Efficient-Graph-Traversal-at-Scale.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.5.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
We are glad to announce the GraphScope 0.5 release. As the first step towards the ease of deployment in production, this major release includes two new features, namely &lt;strong&gt;a persistent graph store&lt;/strong&gt; to enable a “service mode” for real-time graph computing, and &lt;strong&gt;lazy evaluation&lt;/strong&gt; of GraphScope programs–an execution strategy which delays the execution of a GraphScope program until later when needed for efficiency. In addition, we improve the compatibility with NetworkX.
​
We highlight the following improvements included in this release:
​&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;GraphScope-Store: A persistent store for mutable graphs. Currently, it has supported the following features/functions:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;A bulk-load tool to import a property graph from files to the GraphScope-Store instance.&lt;/li&gt;
      &lt;li&gt;Helm support to launch GraphScope as a service with a store.&lt;/li&gt;
      &lt;li&gt;Support for multiple session connections to a store.&lt;/li&gt;
      &lt;li&gt;Interactive queries on graphs in the store with Gremlin.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lazy evaluation&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Support to switch between lazy-mode and eager-mode by just setting the value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt; as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lazy&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eager&lt;/code&gt; when creating a session &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;graphscope.session(mode='lazy'or 'eager')&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;Adapt the NetworkX interfaces to switch between eager and lazy modes.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Enhanced NetworkX compatibility&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Support for multi-queries on duplications of the whole graph.&lt;/li&gt;
      &lt;li&gt;Add all-pairs shortest paths and closeness centrality algorithms.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Provide a &lt;a href=&quot;https://graphscope.io/docs/frequently_asked_questions.html&quot;&gt;Q&amp;amp;A page&lt;/a&gt; for beginners&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.5.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Tue, 15 Jun 2021 03:33:20 +0000</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2021/06/15/release-notes-0.5.0.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/06/15/release-notes-0.5.0.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
      <item>
        <title>Towards a Swiss Army Knife for a Continuous Life Cycle of Big Graph Analytics</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/knife.png&quot; alt=&quot;knife&quot; /&gt;
In this post, we will present a high-level road-map of the GraphScope project with highlighting new exciting features coming in the v0.5 release.&lt;/p&gt;

&lt;h3 id=&quot;how-it-all-gets-started&quot;&gt;How It All Gets Started&lt;/h3&gt;

&lt;p&gt;To begin with, let us reflect on why we start this project. Due to huge diversity of graph data, scenarios, and algorithms, agility is key to the success of a big graph infrastructure, which boils down firstly to the ease of programming and interoperability. GraphScope generalizes previous execution environments such as &lt;a href=&quot;https://giraph.apache.org/&quot;&gt;Giraph&lt;/a&gt; and &lt;a href=&quot;https://spark.apache.org/graphx/&quot;&gt;GraphX&lt;/a&gt; in two ways: by providing a single-machine programming abstraction in Python that supports familiar notations for a variety of graph operations (&lt;a href=&quot;https://tinkerpop.apache.org/&quot;&gt;Gremlin&lt;/a&gt;, &lt;a href=&quot;https://networkx.org/&quot;&gt;NetworkX&lt;/a&gt;, &lt;a href=&quot;https://github.com/alibaba/graph-learn&quot;&gt;Graph Neural Networks&lt;/a&gt;, etc.) while hiding the system complexity from the programmer; and by bridging with other, existing big data infrastructure through &lt;a href=&quot;https://github.com/v6d-io/v6d&quot;&gt;Vineyard&lt;/a&gt; which provides efficient in-memory data transfer with high-level data structures as interface, as shown in Figure 1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/system-stack.png&quot; alt=&quot;system-stack.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Figure 1: The GraphScope system stack, and how it interacts with the &lt;a href=&quot;https://pydata.org/&quot;&gt;PyData&lt;/a&gt; ecosystem.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;a-vision-on-big-graph-infrastructure&quot;&gt;A Vision on Big Graph Infrastructure&lt;/h3&gt;

&lt;p&gt;In addition, we believe big graph infrastructure must be developed for a continuous life cycle. As illustrated in Figure 2, the centered box of “interactive analysis and testing” represents the current version of GraphScope, which facilitates the design of new (or specific) graph algorithms for each particular task in an exploratory manner. As such a process is highly experimental in nature, GraphScope makes it easy to construct and load large graphs on demand and to efficiently perform a wide range of graph computations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/images/lifecycle.png&quot; alt=&quot;lifecycle.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Figure 2: A continuous life cycle of big graph analytics.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once such a design is achieved and selected, it will typically be &lt;em&gt;deployed in production&lt;/em&gt; for processing real dynamic graphs to generate insights in a continuous manner. The left and right box in Figure 2 show two representative processing paradigms for such a deployment: the real-time streaming and the batch-oriented processing, respectively, at two ends of the latency spectrum. In the real-time streaming, ideally, each update to the graph model has to be reflected in the output within a couple of seconds, and therefore the system optimizes for low latency and high availability. In the batch-oriented processing where the latency requirement is much relaxed, it is often more efficient to perform computation periodically (such as every one hour or day) to allow sophisticated optimizations for throughput.&lt;/p&gt;

&lt;h3 id=&quot;graphscope-v05&quot;&gt;GraphScope v0.5&lt;/h3&gt;

&lt;p&gt;As the first step towards the ease of deployment in production, we are introducing two new features in the coming release of GraphScope v0.5, including &lt;em&gt;a persistent graph store&lt;/em&gt; to enable a “service mode” for real-time graph computation, and &lt;em&gt;lazy evaluation&lt;/em&gt; of GraphScope programs–an execution strategy which delays the execution of a GraphScope program until later when needed for efficiency. We briefly introduce them below and will provide more details in the Release Note soon.&lt;/p&gt;

&lt;h4 id=&quot;persistent-graph-store&quot;&gt;Persistent Graph Store&lt;/h4&gt;

&lt;p&gt;In addition to Vineyard, the in-memory columnar graph store currently supported in GraphScope, we will introduce a new disk-based row-oriented multi-versioned persistent graph store. While Vineyard focuses on great support for in-memory whole graph analytics workload, the new persistent graph store is geared towards better supporting for running continuous graph data management service that frequently updates the graph and answers traversal queries.&lt;/p&gt;

&lt;p&gt;The store is a distributed graph store built on top of the popular RocksDB key value store. It adopts row-oriented design to support frequent small updates to the graph. Each row is tagged with a snapshot ID as its version. A query reads most recent version of rows relative to the snapshot ID when it starts and hence not blocked by writes. For writes we take a compromise between consistency and higher throughput (in a similar design to Kineograph [1]). In our design writes in the same session can be grouped and executed atomically as a unit and the persistent store assigns a snapshot ID (which is a low-resolution timestamp of current time) to each group and executes groups of writes by the order of their snapshot IDs and by a deterministic (though arbitrary) order for groups of writes that occur in the same snapshot ID. It provides high write throughput while still with some degree of order and isolation though it provides less consistency than strict snapshot isolation common in database. We hope our design choice provides an interesting trade-off for practical usage.&lt;/p&gt;

&lt;p&gt;Initially, the new persistent store is provided as a separate option from Vineyard. Going foward we hope to evole them into an integrated hybrid graph store suitable for all kinds of workloads.&lt;/p&gt;

&lt;h4 id=&quot;lazy-evaluation&quot;&gt;Lazy Evaluation&lt;/h4&gt;
&lt;p&gt;As an important performance optimization technique, lazy evaluation has been widely applied by many big data processing systems like &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;TensorFlow&lt;/a&gt;. We will introduce the support of lazy evaluation into the coming GraphScope v0.5, which provides three-fold benefits compared with eager evaluation. First, in the lazy evaluation, a job is expressed logically in a directed acyclic graph (DAG) where different nodes represent different operators of the overall job and edges represent the data dependencies between operators. When evaluating the operator (i.e., a vertex in the DAG), GraphScope looks back to check all the nodes that are required for this requested node. Only those nodes are evaluated in the appropriate order. Thus, a node in the DAG is evaluated only when needed; only if it is needed. Second, with the DAG in place, it can avoid repeatedly evaluating the same operator, blindly, regardless whether the operator can be memorized. Third, it allows to combine multiple operators (e.g., adding an edge to a graph) into a single batch-oriented operator (e.g., aggregating multiple edges into a batch and adding the batch to a graph), which is more efficient in GraphScope.&lt;/p&gt;

&lt;p&gt;In GraphScope, developers can easily switch between lazy-mode and eager-mode by just setting the value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt; as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lazy&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eager&lt;/code&gt; when creating a session &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;graphscope.session(mode='lazy'or 'eager')&lt;/code&gt;. Typically, developers can choose the eager-mode in the development stage, as it can ease the debugging of applications, while switch to the lazy-mode in the deployment stage for better performance.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;A tool or infrastructure built for a continuous life cycle of big graph applications requires to do much more than the ease of deployment, but also to help testing and diagnosis of real-world graph applications, and to allow a data-driven approach for continuous evolution of an on-line service or periodic pipeline. Even so, the new features coming in the GraphScope v0.5 release take us one step closer to that vision. Please give it a try and let us know what you think! Really appreciated.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;[1] Raymond Cheng, Ji Hong, Aapo Kyrola, Youshan Miao, Xuetian Weng, Ming Wu, Fan Yang, Lidong Zhou, Feng Zhao, and Enhong Chen. 2012. Kineograph: Taking the Pulse of A Fast-changing and Connected World. In EuroSys ‘12. (&lt;a href=&quot;https://www.cl.cam.ac.uk/~ey204/teaching/ACS/R212_2013_2014/papers/cheng_eurosys_2012.pdf&quot;&gt;pdf&lt;/a&gt;)&lt;/p&gt;
</description>
        <pubDate>Sat, 29 May 2021 03:10:42 +0000</pubDate>
        <link>https://graphscope.io/blog/tech/2021/05/29/Towards-a-Swiss-Army-Knife-for-a-Continuous-Life-Cycle-of-Big-Graph-Analytics.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/tech/2021/05/29/Towards-a-Swiss-Army-Knife-for-a-Continuous-Life-Cycle-of-Big-Graph-Analytics.html</guid>
        
        
        <category>Tech</category>
        
      </item>
    
      <item>
        <title>Release Notes: v0.4.0</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/images/release_note_t.png&quot; alt=&quot;release-note&quot; /&gt;
Today, we’re announcing the availability of GraphScope v0.4.0. This release focuses on
 the compatibility improvement with &lt;a href=&quot;https://networkx.org/&quot;&gt;NetworkX&lt;/a&gt;, with the aim of allowing users to
 develop graph applications on large-scale graphs in a distributed environment just
 like doing this on a single machine. In addition, this release improves the
 experience of standalone deployment.&lt;/p&gt;

&lt;p&gt;We highlight the following improvements included in this release:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Improved compatibility with NetworkX:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Support &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Graph/DiGraph&lt;/code&gt; types in NetworkX;&lt;/li&gt;
      &lt;li&gt;Support Networkx APIs of operations and manipulations over the above two types of graphs;&lt;/li&gt;
      &lt;li&gt;A new &lt;a href=&quot;https://github.com/alibaba/GraphScope/blob/62b3bbff00767784d0bb3693fe9bb24e8a1b4b2a/tutorials/2_graph_manipulations_with_networkx_compatible_apis.ipynb&quot;&gt;tutorial&lt;/a&gt; in Playground to introduce graph processing with NetworkX APIs.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Improve the experience of standalone deployment:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Support to launch multiple sessions/instances in standalone mode.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more detailed improvements that have been made in this release, please refer to the complete &lt;a href=&quot;https://github.com/alibaba/GraphScope/releases/tag/v0.4.0&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Mon, 10 May 2021 05:08:20 +0000</pubDate>
        <link>https://graphscope.io/blog/releasenotes/2021/05/10/release-notes-0.4.0.html</link>
        <guid isPermaLink="true">https://graphscope.io/blog/releasenotes/2021/05/10/release-notes-0.4.0.html</guid>
        
        
        <category>ReleaseNotes</category>
        
      </item>
    
  </channel>
</rss>
